# -*- coding: utf-8 -*-
"""gradCAM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Sinamhd9/Computer-vision-projects/blob/main/Grad-CAM%20saliency%20maps/gradCAM.ipynb

# Grad-CAM saliency algorithm
"""

import keras
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.applications.imagenet_utils import decode_predictions
from keras.preprocessing.image import load_img, img_to_array
import cv2
from google.colab.patches import cv2_imshow
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from keras.models import Model
from IPython.display import display, Markdown

"""## Loading pretrained model"""

model = VGG16()

"""Here is the model summary!"""

model.summary()

"""## Main functions of Grad-CAM

Here, we define a function to load an image from a given path and preprocess it for based on the chosen VGG16 model.
"""

def load_process(img):
  img = load_img(img, target_size = (224, 224))
  img = img_to_array(img)
  img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))
  img = preprocess_input(img)
  return img

"""Now, we define a function to return the top 3 labels predicted by the model."""

def return_labels(img):
  pred = model.predict(img)
  top_labels = decode_predictions(pred, top=3)
  return top_labels[0]

"""Now we write the main gradCam algorithm, that can return multiple top classes with respect to different chosen layers. """

def grad_cam(input_image, model, layer_name, top_class = 1):
  '''
  Main grad_cam algorithm
  '''

  desired_layer = model.get_layer(layer_name)
  grad_model = Model(model.inputs, [desired_layer.output, model.output])

  with tf.GradientTape() as tape:
    layer_output, preds = grad_model(input_image)
    ix = (np.argsort(preds, axis=1)[:, -top_class]).item()
    output_idx = preds[:, ix]

  gradient = tape.gradient(output_idx, layer_output)
  alpha_kc = np.mean(gradient, axis=(0,1,2))
  L_gradCam = tf.nn.relu(np.dot(layer_output, alpha_kc)[0])
  L_gradCam = (L_gradCam - np.min(L_gradCam)) / (np.max(L_gradCam) - np.min(L_gradCam)) 
  return L_gradCam.numpy()

"""Now, we define a function that returns the heatmap and superimposed image of heatmap on top of the base image."""

def blend(original_img, gradCam_img, alpha, colormap = cv2.COLORMAP_JET):
  '''
  Blending images
  '''
  img = img_to_array(load_img(original_img))
  gradCam_resized = cv2.resize(gradCam_img, (img.shape[1], img.shape[0]), interpolation = cv2.INTER_LINEAR)
  print(img.shape)
  print(gradCam_img.shape)
  print(gradCam_resized.shape)
  heatmap  = cv2.applyColorMap(np.uint8(gradCam_resized*255), colormap)
  superimposed_image = cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR) + heatmap * alpha
  return heatmap, superimposed_image

"""Lastly, we define a function that visualize the required outputs. """

def show_results(img_path, layer_name, top_class, alpha=0.5):
  increase_font()
  img = load_process(img_path)
  print(img.shape)
  top_labels_img = return_labels(img)
  for i in range(top_class):
    print('-----------------------------------------------------------')
    grad_cam_img = grad_cam(img, model, layer_name, top_class = i+1)
    plt.imshow(grad_cam_img, cmap='jet')
    plt.show()
    print(top_labels_img[i][1], round(top_labels_img[i][2]*100, 2),'%')
    heatmap_img, result_img = blend(img_path, grad_cam_img, 0.5)
    cv2_imshow(np.concatenate((heatmap_img,result_img), axis=1))

#@title 
# Reference: https://stackoverflow.com/questions/61957742/how-to-increase-font-size-of-google-colab-cell-output
def increase_font():
  from IPython.display import Javascript
  display(Javascript('''
  for (rule of document.styleSheets[0].cssRules){
    if (rule.selectorText=='body') {
      rule.style.fontSize = '30px'
      break
    }
  }
  '''))

"""## Results

### Image 1
"""

show_results('gc1.jpg', 'block5_conv3', top_class = 3, alpha=0.5)

"""### Image 2"""

show_results('gc2.jpg', 'block5_conv3', top_class = 3, alpha=0.5)

"""### Image 3"""

show_results('gc3.jpg', 'block5_conv3', top_class = 3, alpha=0.5)

"""### Image 4"""

show_results('gc4.jpg', 'block5_conv3', top_class = 3, alpha=0.5)

"""### Image 5"""

show_results('gc5.jpg', 'block5_conv3', top_class = 3, alpha=0.5)

"""### Image 6"""

show_results('duke.jpg', 'block5_conv3', top_class = 3, alpha=0.5)

"""## Discussion

Even though, the VGG16 results are not very accurate, the results are interesting! For example, in image 4, the second prediction is acorn_squash, we can see the algorithm is looking at some part of pumpkin and the green leaves around it and concludes it is a acorn_squash. It is also interesting to see the attention of the algorithm when detecting a racer or a tow truck. Basenji prection was very funny since it is looking at the cats' ears and dog's face, it came to Basenji which has a cat shape ear. At last, I did not know the diffrerence between the Shih Tzu (our family's dog), and Lhasa. Imagenet classes showed me this, as we can see in the last image. 
"""

